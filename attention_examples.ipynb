{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hired-humor",
   "metadata": {},
   "source": [
    "## Extract Perplexity & Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imposed-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunrise-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "supported-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fb639f0d710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer and model used throughout\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert_mlm/block_512/bert_mlm_textbook\", output_attentions=True)\n",
    "# Init softmax to get probabilities later on\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accredited-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contexts fed into BERT must start with a [CLS] token and (possibly?) end with a [SEP] token\n",
    "mask_token, mask_id = tokenizer.mask_token, tokenizer.mask_token_id\n",
    "cls_token, cls_id = tokenizer.cls_token, tokenizer.cls_token_id\n",
    "sep_token, sep_id = tokenizer.sep_token, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tamil-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant paths\n",
    "config = \"_128_50\" # window size _ max distance \n",
    "results_folder = \"temporal_attn_examples\" + config + \"/\"\n",
    "low_prob_filename = \"pr_0.25.txt\"\n",
    "mid_prob_filename = \"pr_0.45_0.55.txt\"\n",
    "high_prob_filename = \"pr_0.9999.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "average-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opposing pronouns dictionary\n",
    "man_words = ['man', 'men', 'male', 'he', 'him', 'his']\n",
    "woman_words = ['woman', 'women', 'female', 'she', 'her', 'hers']\n",
    "pronoun_oppos = dict()\n",
    "for i, man_word in enumerate(man_words):\n",
    "    pronoun_oppos[man_word] = woman_words[i]\n",
    "    pronoun_oppos[woman_words[i]] = man_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expired-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pronoun sets\n",
    "man_words_set = set(['man', 'men', 'male', 'he', 'him', 'his'])\n",
    "woman_words_set = set(['woman', 'women', 'female', 'she', 'her', 'hers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "composed-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mask(sentence_data):\n",
    "    tokens_tensor, segments_tensor, tokenized_text, sentence_info, norm_prob = sentence_data\n",
    "    tokens_tensor = torch.tensor(tokens_tensor)\n",
    "    segments_tensor = torch.tensor(segments_tensor)\n",
    "    gender_index, query_index, gender_word, query_word = sentence_info\n",
    "    tokenized_text[gender_index] = mask_token\n",
    "    tokens_tensor[0][gender_index] = mask_id\n",
    "    return tokens_tensor, tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exciting-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_and_probs(inputs, masked_position):\n",
    "    # Forward\n",
    "    outputs = model(inputs)\n",
    "    attention = outputs.attentions  # Output includes attention weights when output_attentions=True\n",
    "    last_hidden_state = outputs[0].squeeze(0)\n",
    "    # Only get output for masked token (output is the size of the vocabulary)\n",
    "    mask_hidden_state = last_hidden_state[masked_position]\n",
    "    # Convert to probabilities (softmax), giving a probability for each item in the vocabulary\n",
    "    probs = softmax(mask_hidden_state)\n",
    "    return attention, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alive-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_prob(probs, gender_word):\n",
    "    man_prob = 0\n",
    "    woman_prob = 0\n",
    "    for m_word in man_words_set:\n",
    "        pronoun_id = tokenizer.convert_tokens_to_ids(m_word)\n",
    "        man_prob += probs[pronoun_id].item()\n",
    "    for w_word in woman_words_set:\n",
    "        pronoun_id = tokenizer.convert_tokens_to_ids(w_word)\n",
    "        woman_prob += probs[pronoun_id].item()\n",
    "    gender_prob = man_prob if gender_word in man_words_set else woman_prob\n",
    "    opp_gender_prob = woman_prob if gender_word in man_words_set else man_prob\n",
    "\n",
    "    norm_prob = gender_prob / (gender_prob + opp_gender_prob)\n",
    "    correctness = 1 if norm_prob > 0.5 else 0\n",
    "    \n",
    "    return norm_prob\n",
    "\n",
    "#     top_word = torch.argmax(probs)\n",
    "#     print('Top Prediction:')\n",
    "#     print(tokenizer.decode(top_word), 'probability', probs[top_word].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-cornwall",
   "metadata": {},
   "source": [
    "## Dissecting Attention Examples\n",
    "\n",
    "Take lowest perplexities and figure out which word has the highest attention with the masked word across each layer?\n",
    "Also need to do for highest perplexity and also see if that's any different! (ie if high perplexity the masked word doesn't attend to the masked word the most or something?\n",
    "\n",
    "Take the higher norm probabilities ones (BERT is predicting the right gender!) and see if there aren't any corefs or syntactic clues; see if either pronoun could be used. Then check attention heads. Compare to lower norm probabilities one in the same case. Could reveal that certain interest words are non-gendered? \n",
    "\n",
    "Layer with the max attention weight?\n",
    "\n",
    "- remember to mask out the pronoun before feeding it into attn viz (as seen in python notebook!)\n",
    "- there's two values u could theoretically look at: weight of <masked gender pronoun> attending to <interest word>, and vice versa. i think the prior makes more sense, since we want to see how much bert is looking at <interest word> when predicting the gender of the masked word! \n",
    "- the above attn analysis pairs well with our 'perplexity' experiment. but another angle we wanted to investigate was a follow-up to our cosine plots. for these, perhaps u could feed in the original sentence (with the gender pronoun UNMASKED), and inspect the weight of <interest word> attneding to <gender pronoun> (note: flopped compared to experiment 1). this would possibly give us insight into whether the interst word is gendered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "western-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_attention(attention):\n",
    "    att_weights = []\n",
    "    for att_layer in attention:\n",
    "        layer = att_layer.squeeze()\n",
    "        layer_weights = layer[:, pronoun_idx, interest_idx].numpy()\n",
    "        att_weights.append(layer_weights)\n",
    "    att_weights = np.stack(att_weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hungry-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05010960765663714\n",
      "0.1267267181875414\n",
      "['[CLS]', 'e', 'activities', 'in', 'much', 'of', 'europe', 'not', 'real', 'work', '.', 'because', 'indian', 'women', 'worked', 'in', 'the', 'fields', 'europeans', 'often', 'described', 'them', 'as', 'lacking', 'freedom', '.', 'they', 'were', 'not', 'much', 'better', 'than', 'slaves', 'in', 'the', 'words', 'of', 'one', 'english', 'commentator', '.', 'europeans', 'considered', 'indian', '[MASK]', 'un', '##man', '##ly', 'too', 'weak', 'to', 'exercise', 'authority', 'within', 'their', 'families', 'and', 'restrain', 'their', 'wives', 'open', 'sexuality', 'and', 'so', 'lazy', 'that', 'they', 'forced', 'their', 'wives', 'to', 'do', 'most', 'of', 'the', 'productive', 'labor', '.', 'throughout', 'north', 'america', 'europeans', 'promoted', 'the', 'ideas', 'that', 'women', 'should', 'con', '##fine', 'themselves', 'to', 'household', 'work', 'and', 'that', 'men', 'ought', 'to', 'exercise', 'greater', 'authority', 'within', 'their', 'families', '.', 'europeans', 'insisted', 'that', 'by', 'sub', '##du', '##ing', 'the', 'indians', 'they', 'were', 'actually', 'bringing', 'them', 'freedom', 'the', 'freedom', 'of', 'true', 'religion', 'private', 'property'] 44\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4bd1405b6c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_norm_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_prob\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mget_norm_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = utilities.read_context_windows(results_folder + low_prob_filename)\n",
    "for sentence_data in data:\n",
    "    tokens_tensor, segments_tensor, tokenized_text, sentence_info, norm_prob = sentence_data\n",
    "    gender_index, query_index, gender_word, query_word = sentence_info\n",
    "    tokens_tensor, tokenized_text = prepare_mask(sentence_data)\n",
    "    attention, probs = get_attention_and_probs(tokens_tensor, gender_index)\n",
    "    print(norm_prob)\n",
    "    print(get_norm_prob(probs, gender_word))\n",
    "    print(tokenized_text, gender_index)\n",
    "    assert(norm_prob == get_norm_prob(probs, gender_word))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-departure",
   "metadata": {},
   "source": [
    "## Attention Head View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from bertviz import head_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert_mlm/block_512/bert_mlm_textbook\", output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"The cat sat on the mat\", return_tensors='pt')\n",
    "outputs = model(inputs)\n",
    "attention = outputs.attentions  # Output includes attention weights when output_attentions=True\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-issue",
   "metadata": {},
   "source": [
    "## Attention Neuron View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import specialized versions of models (that return query/key vectors)\n",
    "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
    "from bertviz.neuron_view import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model = BertModel.from_pretrained('bert_mlm/block_512/bert_mlm_textbook', output_attentions=True)\n",
    "model_type = 'bert'\n",
    "sentence = \"The cat sat on the mat\"\n",
    "show(model, model_type, tokenizer, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
