Chapter 42 The American People Face a New Century


 especially in genetics and computer applications, presented Americans with stunning opportunities as well as wrenching ethical choices. Ecological dangers made the responsible stewardship of a fragile planet more urgent than ever. Inequality and prejudice continued to challenge Americans to close the gap between their most hallowed values and the stark realities of modern life. And the terrorist attacks of September 11, 2001, violently heralded a new era of fear and anxiety. But men and women make history only within the framework bequeathed to them by earlier generations. For better or worse, they march forward along time’s path bearing the burdens of the past. Knowing when they have come to a truly new turn in the road, when they can lay part of their burden down and when they cannot, or should not—all this constitutes the sort of wisdom that only historical study can engender.

Economic Revolutions
 When the twentieth century opened, United States Steel Corporation was the ﬂagship business of America’s booming industrial revolution. A generation later, General Motors, annually producing millions of automobiles, became the characteristic American corporation, signaling the historic shift to a mass consumer

Outsourcing Jobs to India
 Sophisticated computer technology has allowed developing countries like India to attract Western employers seeking lower labor costs. India’s educated and Englishspeaking work force has made it particularly suitable for international call centers and computer programming.

 economy that began in the 1920s and ﬂowered fully in the 1950s. Following World War II, the rise of International Business Machines (IBM) symbolized yet another momentous transformation, to the fast-paced “information age,” when the storing, organizing, and processing of data became an industry in its own right. The pace of the information age soon accelerated. By century’s end the rapid emergence of Microsoft Corporation and the phenomenal growth of the Internet heralded an explosive communications revolution. Americans now rocketed down the “information superhighway” toward the uncharted terrain of an electronic global village, where traditional geographic, social, and political boundaries could be vaulted with the tap of a keypad. The communications revolution was full of both promise and peril. In the blink of an eye, ordinary cit izens could gain access to information once available only to privileged elites with vast libraries or expert staffs at their disposal. Businesspeople instantaneously girdled the planet with transactions of prodigious scope and serpentine complexity. Japa nese bankers might sell wheat contracts in Chicago and simultaneously direct the proﬁts to buying oil shipments from the Persian Gulf offered by a broker in Amsterdam. By the late 1990s, a “dot-com” explosion of new commercial ventures quickly expanded the mar-

The Economy and Technology




Index
5,000


4,500


4,000


3,500
3,000


2,500


2,000
1,500
1,000




















 ket (and the stock-market stakes) for entrepreneurs leading the way in making the Internet a twenty-ﬁrstcentury electronic mall, town square, library, and entertainment center rolled into one. But the very speed and efﬁciency of the new communications tools threatened to wipe out entire occupational categories. Postal carriers, travel agents, store clerks, bank tellers, stockbrokers, and all kinds of other workers whose business it was to mediate between product and client might ﬁ nd themselves roadkill on the information superhighway. White-collar jobs in ﬁ nancial ser vices and high-tech engineering, once thought securely anchored in places like Chicago, Los Angeles, and New York, could now be “outsourced” to countries such as Ireland and India, where employees could help keep a company’s global circuits ﬁ ring twenty-four hours a day. The high-tech economy also proved to be as prone to boom and bust as the old smokestack economy. In the spring of 2000, the stock market began its most precipitous slide since the Second World War. By the time the markets bottomed out in 2003, they had lost $6 trillion in value (see Figure 42.1). The boom of the late 1990s turned out to be, as one observer put it, the “Dot.con.” Investors had scooped up shares in ﬂedgling ﬁ rms that proved unable to turn a proﬁt, and stock prices imploded accordingly once the bubble burst. Millions of Americans watched aghast as their pension plans shrank by a third or more. Recent retir-











Figure 42.1 The Rise
 and Fall of the NASDAQ Composite Index, 1994– 2004 In March 2000 the NASDAQ Composite Index, replete with technology stocks, peaked at its alltime closing high of 5,048 before losing over 75 percent of its market value in the next three years. The same index had opened in February 1971 with a base valuation of 100 points. (Source: MSN Money.)

 ees scrambled back into the job market. The economic turbulence of the ﬁ rst years of the century stood as a sober reminder that even as the American economy generated extraordinary wealth and innovation by global standards, it was scarcely immune to the ageold vagaries of risk, error, scandal, and the business cycle. Increasingly, scientiﬁc research was the motor that propelled the economy, and new scientiﬁc knowledge raised new moral dilemmas and provoked new political arguments. When scientists ﬁ rst unlocked the secrets of molecular genetic structure in the 1950s, the road lay open to breeding new strains of high-yield, pest- and weather-resistant crops; to curing hereditary diseases; and also, unfortunately, to unleashing genetic mutations that might threaten the fragile balance of the wondrous biosphere in which humankind was delicately suspended. By the dawn of the new century, scientists stood at the threshold of a revolution in biological engineering. The Human Genome Project established the DNA sequencing of the thirty thousand human genes, pointing the way to radical new medical therapies—and to mouthwatering proﬁts for bioengineering ﬁ rms. Startling breakthroughs in the cloning of animals raised thorny questions about the legitimacy of applying cloning technology to human reproduction. Research into human stem cells held out the promise of cures for afﬂ ictions like Parkinson’s disease and Alzheimer’s. But the Bush administration



Chapter 42 The American People Face a New Century


 shared the concern of certain religious groups that harvesting stem cells involved the destruction of human life in embryonic form. Bush therefore limited government funding for stem cell research, as Americans continued to struggle with the ethical implications of their vast new technological powers. Other unprecedented ethical questions clamored for resolution. What principles should govern the allocation of human organs for lifesaving transplants? Was it wise in the ﬁ rst place to spend money on such costly procedures rather than devote society’s resources to improved sanitation, maternal and infant care, and nutritional and health education? How, if at all, should society regulate the increasingly lengthy and often painful process of dying? (See “Makers of America: Scientists and Engineers,” pp. 1088–1089.)

 Afﬂuence and Inequality Americans were still an afﬂuent people at the beginning of the twenty-ﬁ rst century. Median household income declined somewhat in the early 1990s but reached $48,200 in 2006. Yet even those Americans with incomes below the government’s ofﬁcial poverty level (deﬁ ned in 2007 as $20,650 for a family of four) enjoyed a standard of living higher than that of twothirds of the rest of humankind.

 Americans were no longer the world’s wealthiest people, as they had been in the quarter-century after World War II. Citizens of several other countries enjoyed higher average per capita incomes, and many nations boasted more equitable distributions of wealth (see Map 42.1). In an unsettling reversal of long-term trends in American society, during the last two decades of the twentieth century, the rich got much richer, while the poor got an ever-shrinking share of the pie. The richest 20 percent of Americans in 2006 raked in over half the nation’s income, while the poorest 20 percent received a little over 3 percent (see Table 42.1). The gap between rich and poor began to widen in the 1980s and widened further thereafter. That trend was evident in many industrial societies, but it was most pronounced in the United States. Between 1968 and 2006, the share of the nation’s income that ﬂowed to the top 20 percent of its households swelled from 40 percent to 50.5 percent. Even more striking, in the same period the top 5 percent of income earners saw their share of the national income grow from about 15 percent to a remarkable 22.3 percent. The Welfare Reform Bill of 1996, restricting access to social ser vices and requiring able-bodied welfare recipients to ﬁnd work, weakened the ﬁ nancial footing of many impoverished families still further. Widening inequality could be mea sured in other ways as well. In the 1970s chief executives typically

 Two Nations? While decaying neighborhoods and legions of the homeless blighted American cities in the early twenty-ﬁ rst century, afﬂuent Americans lived the good life in booming suburbs and in the more suburbanized cities of the Sunbelt, such as this development of million-dollar homes around a country club in Las Vegas, Nevada.

Widening Inequality


Table 42.1 Widening Income Inequality
Share of Aggregate
Income










Lowest ﬁ fth
Second ﬁ fth
Third ﬁ fth
Fourth ﬁ fth
Highest ﬁ fth
Top 5%


4.2
10.2
16.8
24.7
44.1
16.5


3.8
9.6
15.9
24.0
46.6
18.5


3.6
8.9
14.8
23.0
49.8
22.1


3.4%
8.6
14.6
23.0
50.4
22.2


 During the last two decades of the twentieth century, the top ﬁ fth of the country’s households made signiﬁcant gains in income, while everyone else lost ground. (Source: Statistical Abstract of the United States, 2008)

 earned forty-one times as much as the average worker in their corporations; by the early 2000s, they earned 245 times as much. In 2006, 47 million people had no medical insurance. At the same time, some 36.5 mil-

 lion people, 12.3 percent of all Americans (8.2 percent of whites, 24.3 percent of African Americans, 20.6 percent of Latinos, and 10.3 percent of Asians), remained mired in poverty—a depressing indictment of the inequities afﬂicting an afﬂuent and allegedly egalitarian republic. What caused the widening income gap? Some critics pointed to the tax and ﬁscal policies of the Reagan and both Bush (father and son) presidencies, which favored the wealthy (see Table 42.2). But deeperrunning historical currents probably played a more powerful role, as suggested by the similar experiences of other industrialized societies. Among the most conspicuous causes were intensifying global economic competition; the shrinkage in high-paying manufacturing jobs for semiskilled and unskilled workers; the greater economic rewards commanded by educated workers in high-tech industries; the decline of unions; the growth of part-time and temporary work; the rising tide of relatively low-skill immigrants; and the increasing tendency of educated men and women to

 DENMARK

 IRELAND

NORWAY UNITED KINGDOM
$1,406 billion 
 CANADA $677 billion

 NETHERLANDS

 SWEDEN

 FINLAND

 GERMANY $1,874 billion

 BELGIUM

RUSSIA POLAND

 FRANCE $1,303 billion

UNITED STATES
$10,171 billion 


CZECH REP. HUNGARY

SWITZER- AUSTRIA LAND

GREECE SPAIN PORTUGAL
$578 billion 
 MEXICO $618 billion

 ITALY $1,091 billion

 ALGERIA

 TURKEY

I
I R
RA I AN S Q R A S E AA L UR DA I B EGYPT I A

 PAKISTAN

 JAPAN $4,245 billion

 TAIWAN

BANGLADESH INDIA
$478 billion THAILAND 
SOUTH AFRICA

VENEZUELA COLOMBIA

REP. KOREA

 CHINA $1,159 billion

MALAYSIA SINGAPORE

PHILIPPINES INDONESIA

 BRAZIL $503 billion

 PERU

 AUSTRALIA

 CHILE

 Per capita income Over $20,000

 ARGENTINA

 One square represents $20 billion in GDP

$10,000–$19,999
$2,000–$9,999
Under $2,000


Map 42.1 Global Distribution of Wealth


NEW ZEALAND

 The top fifty countries are named; the GDP of the top twelve is listed.

Interactive Map


MAKERS OF

AMERICA
Scientists and The Great AfricanEngineers American Migration 
S


 ubatomic particles and space-bound satellites do not respect political boundaries. Disease-carrying viruses spread across the globe. Radio waves and Internet communications reach every corner of planet Earth. At ﬁ rst glance science, technology, and medicine appear to be quintessentially international phenomena. Scientists often pride themselves on the universal validity of scientiﬁc knowledge and the transnational character of scientiﬁc networks. In a world marked by political divisions, science evidently knows no bounds. But a closer look reveals that national context does inﬂuence the character of scientiﬁc enterprise. American scientists have repeatedly made signiﬁcant contributions to the life of the nation. They, in turn, have been shaped by its unique historical circumstances— especially America’s intensifying concerns about national security in the twentieth century. Once marginal players in global intellectual life, American scientists now stand at the forefront of scientiﬁc advancement. In many ways the rise of American science has kept pace with the arrival of the United States as a world power. Nowhere was this trend more evident than in the story of “Big Science.” The unusual demands of America’s national security state during World War II and the Cold War required vast scientiﬁc investments. The result was Big Science, or multidisciplinary research enterprises of unparalleled size, scope, and cost. Big Science and Big Technology meant big bucks, big machines, and big teams of scientists and engineers. The close link between government and science was not new—precedents stretched as far back as the founding of the National Academy of Sciences during the Civil War. But the depression-era Tennessee Valley Authority (TVA) and the wartime Manhattan Project ushered in ventures of colossal scale and ambition. As the head of the TVA wrote in 1944, “There is almost nothing, however fantastic, that (given competent orga ni zation) a team of engineers, scientists, and administrators can not do today.” Cold War competition with the Soviets translated into huge government investments in physics, chemistry, and aerospace. The equation was simple: national security depended on technological superiority, which entailed costly facilities for scientiﬁc research and ambitious efforts to recruit and train scientists. In the 1950s defense projects employed two-thirds of



 Launching Apollo 11 NASA ﬂight directors monitor the launch of the Apollo 11 lunar landing mission from the Manned Spacecraft Center in Houston, Texas, in July 1969.

 the nation’s scientists and engineers. Laboratories, reactors, accelerators, and observatories proliferated. After the Soviets launched the world’s ﬁ rst artiﬁcial satellite (Sputnik I) in 1957, the international space race became America’s top scientiﬁc priority. To land astronauts on the moon, the National Aeronautics and Space Administration (NASA) spent a whopping $25.4 billion over eleven years on Project Apollo. Another massive aerospace mission, President Reagan’s controversial Strategic Defense Initiative (or “Star Wars”), consumed somewhere between $32 billion and $71 billion between 1984 and 1994. In America’s burgeoning “research universities,” the federal government found willing partners in the promotion of the scientiﬁc enterprise. University-employed scientists, largely paid by government grants, concentrated on basic research, accounting for over half of the estimated $50 billion spent on basic science in 2002. Meanwhile, private industry spent additional billions on applied research and product development. For consumers of air bags, silicon chips, and other high-tech gadgets, these investments yielded rich rewards as innovative technologies dramatically improved the quality of life. Over the course of the twentieth century, American corporations spearheaded a global revolution in communications and information technology. American Telephone and Telegraph (AT&T) and Radio Corporation of America (RCA) attended the birth of telephones, radio, and television. Apple, International

 Business Machines (IBM), and Microsoft introduced personal computers. Government and industry scientists together invented the Internet. Twentieth-century advances in medical science and technology have also revolutionized American lives. Thanks to new drugs, devices, and methods of treatment, the average life expectancy in the United States leapt from 47.3 years in 1900 to 77.0 years in 2000. In the ﬁ rst half of the twentieth century, physicians discovered hormones and vitamins, introduced penicillin and other antibiotics, and experimented with insulin therapy for diabetes and radiation therapy for cancer. More recently, cutting-edge medical science has nurtured in vitro fertilization; developed respirators, artiﬁcial hearts, and other medical devices; and attacked (though with limited success) the AIDS epidemic. Much of the optimism for future medical breakthroughs centers on the $3 billion Human Genome Project, which completed its mapping and sequencing of all the genetic material in the human body in 2003. Deemed the “holy grail” of genomics research, the project promised countless beneﬁts, including new diagnoses for genetic defects, innovative therapies, and untold commercial applications. Coordinated by the Department of Energy and the National Institutes of Health, the project involved thousands of scientists in universities and laboratories across the nation and around the globe. To achieve such innovation, Big Science typically demands complex teams of scientists, engineers, and technicians. When traditional channels of recruitment

A
Scientist Working in Her Lab This medical school professor researching pancreatic regeneration was part of the surge of women pursuing scientiﬁc careers, particularly in the biological sciences. By 2004 as many women as men enrolled in medical schools, and minority enrollment climbed as well. In that year 7 percent of entering medical students were Latino, and 6.5 percent were African American. 
Percent












Female


Black


Latino


 Foreign-born

 Figure 42.2 Demographic Proﬁle of Women, Minorities, and the Foreign-born in Nonacademic Science and Engineering Occupations, 1980–2000 (Source: Science and Engineering Indicators, 2002, http://www.nsf.gov/ statistics/seind02/c3/ﬁg03-13.htm.)

 came up short, scientiﬁc institutions increasingly recruited foreigners, women, and minorities (see Figure 42.2). Immigrants and exiles played key roles in the development of the atomic bomb and Cold War weaponry. Long relegated to ju nior positions as assistants and technicians, women and minorities have recently made signiﬁcant gains in the “white man’s world” of science. In 2001 women represented 26 percent of employed doctoral scientists and engineers in the United States, the foreign-born 24 percent, and minorities 21 percent. Despite these stunning achievements, current evidence suggests that the United States might be losing its preeminence in science. After dominating the intellectual world from the 1960s through the 1990s, American scientists are now winning fewer prizes and patents and publishing fewer scientiﬁc papers than their peers in Europe and Asia. Experts predict that current schoolage Americans will not be able to meet the rising demand for scientiﬁc ex per tise. Moreover, fewer foreigners will arrive to ﬁ ll the gap, as international competition for their labor heats up in places like Japan, China, and India. For the United States to retain preeminence in science in the twenty-ﬁ rst century, it must continue to welcome all talent to the ﬁeld. That means attracting both foreign-born scientists and young American students whose brainpower has long helped make the nation a scientiﬁc power.



Chapter 42 The American People Face a New Century


Table 42.2 Who Pays Federal Income Taxes?
 (share of U.S. income tax, by income percentile) Income Group (base income shown as of 2006)





 Top 1% (above $328,049) Top 5% (above $137,056) Top 10% (above $99,112) Top 25% (above $60,041) Top 50% (above $30,122) Bottom 50% (below $30,122)

28.7%
47.4
59.1
79.5
95.2
4.8


36.9%
57.1
68.2
84.9
96.7
3.3


 Because the United States has long had a “progressive” income tax system, in which tax obligations are distributed according to ability to pay, widening income inequality was reﬂected in a redistribution of tax burdens. In the booming 1990s, the rich did indeed get richer—but they also paid an increasing fraction of the total federal tax take. These ﬁgures help explain why tax cuts beneﬁt the wealthy more than middle-income earners and the poor.

COUNTRY
United States 


United Kingdom




France




Germany




China




Japan




India




Russia
























Percentage


Figure 42.3 Women in the Work Force Globally,


 (Source: Internal Revenue Service data, Tax Foundation; http://www .taxfoundation.org/news/show/250.html)

 marry one another and both work, creating households with very high incomes. Educational opportunities also had a way of perpetuating inequality, starting with the underfunding of many schools in poor urban areas and the soaring cost of higher education. A 2004 study revealed that at the 146 most selective colleges, 74 percent of the students came from families with incomes in the top 25 percent, compared to 3 percent of the students from the bottom income quartile.

The Feminist Revolution
 All Americans were caught up in the great economic changes of the late twentieth century, but no group was more profoundly affected than women. When the century opened, women made up about 20 percent of all workers. Over the next ﬁve decades, they increased their presence in the labor force at a fairly steady rate, except for a temporary spurt during World War II. Then, beginning in the 1950s, women’s entry into the workplace accelerated dramatically. By the 1990s nearly half of all workers were women, and the majority of working-age women held jobs outside the home. Most astonishing was the upsurge in employment among mothers. In 1950 nearly 90 percent of mothers with children under the age of six did not work for pay. But half a century later, a majority of women with chil-

 dren as young as one year old were wage earners (see Table 42.3). Women now brought home the bacon and then cooked it, too. By 2004 American women participated in the work force in higher numbers than in almost all industrialized countries except Russia and China (see Figure 42.3). Beginning in the 1960s, many all-male strongholds, including Yale, Princeton, West Point, and even, belatedly, southern military academies like the Citadel and Virginia Military Institute, opened their doors to women. By the twenty-ﬁ rst century, women were piloting airliners, orbiting the earth, governing states and cities, and writing Supreme Court decisions.

Table 42.3 Percentage of Working Married
 Women with Children (husband present), 1950–2005 Year

Total
No Children
Percentage
Under 18
23.8%
30.5
40.8
50.1
60.6
60.2


30.3%
34.7
42.2
46.0
53.2
53.6


Children
6–17 Only


Children
Under 6


28.3%
39.0
49.2
61.7
76.0
75.0


 (Source: Statistical Abstract of the United States, relevant years.)

11.9%
18.6
30.3
45.1
61.7
59.8


Women and Families




A
New World for Women By the beginning of the twenty-ﬁrst century, revolutionary changes in the economy and in social values had opened new career possibilities to women, even while they still performed their traditional duties as mothers and homemakers. Commander Kathleen McGrath of the frigate USS Jarrett (bottom left) was the ﬁrst woman to take a warship to sea in 2000, and Drew Gilpin Faust (bottom right) became the ﬁrst woman to serve as president of Harvard University in 2007. Women athletes came into their own in the wake of the feminist revolution. Venus and Serena Williams (top right) enthralled the tennis world as individual champions and as a doubles team beginning in the late 1990s. 
 Yet despite these gains, many feminists remained frustrated. Women continued to receive lower wages— less than 81 cents on the dollar in 2006—compared with men doing the same full-time work. They also tended to concentrate in a few low-prestige, low-paying occupations (the “pink-collar ghetto”). Although they made up more than half the population, women in 2006 accounted for just 32 percent of lawyers and judges (up from 5 percent in 1970) and 32 percent of physicians (up from 10 percent in 1970). Overt sexual

 discrimination explained some of this occupational segregation, but most of it seemed attributable to the greater burdens of parenthood on women than on men. Women were far more likely than men to interrupt their careers to bear and raise children, and even to choose less demanding career paths to allow for fulﬁ lling those traditional roles. Discrimination and a focus on children also helped account for the persistence of a “gender gap” in voting behavior. Women continued to vote in greater numbers than men for



Chapter 42 The American People Face a New Century


 Democratic candidates, who were often perceived as being more willing to favor government support for health and child care, education, and job equality, as well as being more vigilant to protect abortion rights. As the revolution in women’s status rolled on in the 2000s, men’s lives changed as well. Some employers provided paternity leave in addition to maternity leave, in recognition of the shared obligations of the two-worker household. More men assumed traditional female responsibilities such as cooking, laundry, and child care. Recognizing the new realities of the modern American household, Congress passed a Family Leave Bill in 1993, mandating job protection for working fathers as well as mothers who needed to take time off from work for family-related reasons.

New Families and Old
 The traditional nuclear family, once prized as the foundation of society and the nursery of the Republic, suffered heavy blows in modern America. By the 1990s one out of every two marriages ended in divorce. Seven times more children were affected by divorce than at the beginning of the twentieth century. Kids who

The Modern Family Tree
 High divorce rates and the increasing number of “blended families” in modern American society could make for confusing “family trees.”

 commuted between separated parents were commonplace. The old ideal of a family with two parents, only one of whom worked, was now a virtually useless way to picture the typical American household. Traditional families were not only falling apart at an alarming rate but were also increasingly slow to form in the ﬁ rst place. The proportion of adults living alone tripled in the four decades after 1950, and by the 1990s nearly one-third of women aged twenty-ﬁve to twenty-nine had never married. In the 1960s, 5 percent of all births were to unmarried women, but three decades later one out of four white babies, one out of three Latino babies, and two out of three African American babies were born to single mothers. Every fourth child in America was growing up in a household that lacked two parents. The collapse of the traditional family contributed heavily to the pauperization of many women and children, as single parents (usually mothers) struggled to keep their households economically aﬂoat. Single parenthood outstripped race and ethnicity as the most telling predictor of poverty in America. Child-rearing, the family’s foremost function, was being increasingly assigned to “parent-substitutes” at day-care centers or schools—or to television, the mod-

The Elderly and Social Security




 ern age’s “electronic baby-sitter.” Estimates were that the average child by age sixteen had watched up to ﬁ fteen thousand hours of TV—more time than was spent in the classroom. Parental anxieties multiplied with the advent of the Internet—an electronic cornucopia where youngsters could “surf” through poetry and problem sets as well as pornography. But if the traditional family was increasingly rare, the family itself remained a bedrock of American society in the early twenty-ﬁ rst century, as viable families now assumed a variety of forms. Children in households led by a single parent, stepparent, or grandparent, as well as children with gay or lesbian parents, encountered a degree of acceptance that would have been unimaginable a generation earlier. Even the notion of gay marriage, which emerged as a major public controversy when the Massachusetts Supreme Court ruled it legal in 2003, signaled that the idea of marriage retained its luster. Teenage pregnancy, a key source of single parenthood, was also on the decline after the mid-1990s. Even divorce rates appeared to ebb a bit, with 4 divorces per thousand people in 2007, down from 5.3 per thousand in 1981. The family was not evaporating, but evolving into multiple forms.

The Aging of America
 Old age was more and more likely to be a lengthy experience for Americans, who were living longer than ever before. A person born at the dawn of the century could expect to survive less than ﬁ fty years, whereas someone born in 2000 could anticipate a life span of seventy-seven years. (The ﬁgures were slightly lower for nonwhites, reﬂecting differences in living standards, especially diet and health care.) The census of 1950 recorded that women for the ﬁ rst time made up a majority of Americans, thanks largely to greater female longevity. Miraculous medical advances lengthened and strengthened lives. Noteworthy were the development of antibiotics after 1940 and Dr. Jonas Salk’s discovery in 1953 of a vaccine against a dreaded crippler, polio. Longer lives spelled more older people. One American in eight was over sixty-ﬁve years of age in 2005, and projections were that one of every ﬁve people would be in the “sunset years” by 2050, as the median age rose toward forty. This aging of the population raised a host of political, social, and economic questions. Elderly people formed a potent electoral bloc that aggressively lobbied for government favors and

 Senior Power Living longer and living healthier, older Americans coalesced into one of America’s most politically powerful interest groups in the early twentyﬁrst century.

 achieved real gains for senior citizens. The share of GNP spent on health care for people over sixty-ﬁve more than doubled in the three decades after the enactment of Medicare in 1965. This growth in medical payments for the old far outstripped the growth of educational expenditures for the young, with corresponding consequences for the social and economic status of both populations. As late as the 1960s, nearly a quarter of Americans over the age of sixty-ﬁve lived in poverty; three decades later only about one in ten did. The ﬁgures for young people moved in the reverse direction: whereas 15 percent of children were living in poverty in the 1970s, nearly 17 percent were poor in 2002. These triumphs for senior citizens also brought ﬁscal strains, especially on the Social Security system, established in 1935 to provide income for retired workers. Before Social Security began, most workers continued to toil after age sixty-ﬁve. By century’s end only a small minority did (about 15 percent of men



Chapter 42 The American People Face a New Century


 and 8 percent of women), and a majority of the elderly population relied primarily on Social Security checks for their living expenses. Contrary to popular mythology, Social Security payments to retirees did not represent reimbursement for contributions that the elderly had made during their working lives. In fact, the payments of current workers into the Social Security system funded the beneﬁts to the current generation of retirees. By the time the new century opened, those

 Billions of dollars 1,400 1,300 1,200 1,100 1,000 1930 ’35 ’40 ’45 ’50 ’55 ’60 ’65 ’70 ’75 ’80 ’85 ’90 ’95 2000 ’05

Figure 42.4 Government Expenditures for Social
 Welfare, 1930–2005 “Social welfare” includes unemployment and old-age insurance, health care, and veterans’ beneﬁts. The skyrocketing costs from the mid-1960s onward reﬂect new commitments made through Great Society programs and the increasing size (and political clout) of the elderly population, who were the main beneﬁciaries of expensive programs like Medicare. The steep rise after 1970 is also explained by the galloping inﬂation of the 1970s. (Sources: Statistical Abstract of the United States, 2003; Ofﬁce of Management and Budget, 2005 and 2006, http://www.whitehouse.gov/omb/ budget/fy2005/ tables.html.)

 beneﬁts had risen so high, and the ratio of active workers to retirees had dropped so low, that drastic adjustments were necessary. The problem intensiﬁed as elders found that health-care costs, especially prescription drugs and long-term nursing care, were rising at a far faster clip than their retirement beneﬁts were designed to cover. At the beginning of the new century, as the huge wave of post–World War II baby boomers approached retirement age, it seemed that the “unfunded liability”—the difference between what the government had promised to pay to the elderly and the taxes it expected to take in—might rise above $7 trillion, a sum that threatened to bankrupt the Republic unless drastic reforms were adopted. Yet because of the electoral power of older Americans, Social Security and Medicare reform remained the “third rail” of American politics, which politicians touched only at their peril (see Figure 42.4). Pressures mounted nonetheless to cut beneﬁts, persuade older Americans to work longer, or take even more drastic action. In 2005 freshly reelected President George W. Bush made Social Security reform the centerpiece of his domestic agenda and proposed partially privatizing the system. Bush’s plan would have given younger workers the option to invest some of their payroll taxes in individual retirement funds. But the electoral power of older Americans and the country’s ultimate loyalty to a public social safety net brought the Bush plan to a stunningly quick halt that spring. Plans to reshape the Social Security system lay dormant for the rest of the Bush years, even as some analysts claimed that payments to the nonworking elderly threatened to soak up fully half of the working population’s income by about 2040.

The New Immigration
 Newcomers continued to ﬂow into modern America. They washed ashore in waves that numbered nearly 1 million persons per year from the 1980s into the early twenty-ﬁ rst century—the largest inﬂow of immigrants in America’s experience. In striking contrast to the historic pattern of immigration, Europe contributed far fewer people than did Asia and Latin America (see Figure 42.5). And unlike their predecessors, many of the new immigrants settled not only in traditional ethnic enclaves in cities and towns but also in the sprawling suburbs of places like Los Angeles, Dallas, and Atlanta, where many of the new jobs were to be found.

Immigration and Assimilation




 In thousands 4,000 1961–1970 3,500

1971–1980
1981–1990


3,000


1991–2000
2001–2006


2,500


2,000


1,500


1,000




Europe


Asia


Africa


Mexico,
Caribbean,
Central America


South
America


Figure 42.5
Recent Legal Immigration by Area of Origin, 1961–2006
(Source: Yearbook of Immigration Statistics, 2002 and 2006, Department of Homeland Security.)


 What prompted this new migration to America? The truth is that the newest immigrants came for many of the same reasons as the old. They typically left countries where populations were growing rapidly and where agricultural and industrial revolutions were shaking people loose from old habits of life— conditions almost identical to those in nineteenthcentury Europe. And they came to America, as previous immigrants had done, in search of jobs and economic opportunity. Some came with skills and even professional degrees, from India or Taiwan or the former Soviet Union, and they found their way into middle-class jobs. But most came with fewer skills and less education, seeking work as janitors, nannies, farm laborers, lawn cutters, or restaurant workers. The Southwest, from Texas to Cal i fornia, felt the immigrant impact especially sharply, as Mexican migrants—by far the largest contingent of modern immigrants—concentrated heavily in that region. By the turn of the century, Latinos made up nearly one-third of the population in Texas, Arizona, and Cal i fornia and 40 percent in New Mexico—amounting to a demo-

 graphic reconquista of the lands lost by Mexico in the war of 1846–1848. (see “Makers of America: The Latinos,” pp. 1098–1099). The size and geographic concentration of the Latino population in the Southwest had few precedents in the history of American immigration. Most previous groups had been so thinly scattered across the land that they had little choice but to learn Eng lish and make their way in the larger American society, however much they might have longed to preserve their native language and customs. But it seemed possible that Mexican Americans might succeed in creating a truly bicultural zone in the booming southwestern states, especially since their mother culture lay accessible just next door. Some old-stock Americans worried about the capacity of the modern United States to absorb these new immigrants. The Immigration Reform and Control Act of 1986 attempted to choke off illegal entry by penalizing employers of undocumented aliens and by granting amnesty to many of those already here.



Chapter 42 The American People Face a New Century


 Changing Colors A second-grade bilingual class recites the Pledge of Allegiance (in both Spanish and English) in Austin, Texas. By the end of the twentyﬁrst century, Americans who will be able to trace their ancestry directly to Europe might well be a minority in the United States.

 Yet the fact was that foreign-born people accounted for only about 12.1 percent of the American population in 2005, a far smaller proportion than the historical high point of nearly 15 percent recorded in the census of 1910, but evidence nonetheless that American society continued to welcome—and need— newcomers. Somewhat inconsistently, critics charged both that immigrants robbed citizens of jobs and that they dumped themselves on the welfare rolls at the taxpayers’ expense. But studies showed that immigrants took jobs scorned by Americans and that they paid more dollars in federal taxes (withholding and Social Security taxes, as well as excise taxes) than they claimed for welfare payments. The story was different at the state level, where expenditures for immigrant education and health care often exceeded the net tax contribution of the immigrants themselves. Yet the infusion of young immigrants and their offspring was just what the country needed when faced with the challenges of an aging population. A more urgent worry was that unscrupulous employers might take cruel advantage of alien workers, who often had scant knowledge of their legal rights. Debates over immigration were complicated by the problem of illegal immigrants. The intensity mounted in 2006, when xenophobic pundits and politicians fanned the old ﬂames of anxiety that millions of undocumented workers were usurping American tax dollars and privileges. Immigrant sympathizers argued that unlawful

 aliens had to be legalized so that they could receive the same protections as other workers. Amid this chaos President George W. Bush and a bi-partisan group of legislators proposed a law to establish a guest-worker program for undocumented workers and create a path to citizenship, albeit after paying a ﬁne. Anti-immigrant forces condemned the plan as “amnesty.” Business interests protested that it put too great a burden on employers to verify the right to work. And immigrant rights advocates claimed that it would create “second-class citizens.” In the end, the compromise bill pleased no one and fell into the dustbin. But the debate’s legacy was large. The anti-immigrant venom spewed by many Republican politicians undercut hopes that the GOP might continue to attract Latino voters as it had in the 2004 presidential election, when many of them embraced the party’s conser vative positions on social values.

Beyond the Melting Pot
 Thanks both to continued immigration and to their own high birthrate, Latinos were becoming an increasingly important minority. The United States by 2006 was home to about 44 million of them. They included some 26 million Chicanos, or Mexican Americans, mostly in the Southwest, as well as 3 million Puerto Ricans, chieﬂy in the Northeast, and more than 1 million Cubans in Florida (where it was jokingly

A
Multicultural Society 



The Oldest Americans
Members of the Cheyenne
 River Sioux Tribe celebrate the opening of the Smithsonian Institution’s National Museum of the American Indian in Washington, D.C., 2004.

 said that Miami had become the most “Anglo” city in Latin America). Flexing their political muscles, Latinos elected mayors of Miami, Denver, San Antonio, and Los Angeles. After years of struggle, the United Farm Workers Organizing Committee (UFWOC), headed by the softspoken and charismatic César Chávez, succeeded in improving working conditions for the mostly Chicano “stoop laborers” who followed the cycle of planting and harvesting across the American West. Latino inﬂuence seemed likely to grow, as suggested by the increasing presence of Spanish-language ballots and television broadcasts. Latinos, newly conﬁdent and orga nized, became the nation’s largest ethnic minority, outnumbering even African Americans, in 2003. Indeed by the early twenty-ﬁ rst century, the Chicano population of America’s largest state, Cal i fornia, led the Anglo population, making the state a patchwork of minorities with no single ethnic majority. In 2003 most newborns in Cal i fornia were Latino, a powerful harbinger of the state’s demographic future. Asian Americans also made great strides. By the 1980s they were America’s fastest-growing minority, and their numbers reached nearly 12 million by 2002. Once feared and hated as the “yellow peril” and consigned to the most menial and degrading jobs, citi-

 zens of Asian ancestry were now counted among the most prosperous Americans. Indians, the original Americans, numbered some 2.4 million in the 2000 census. Half of them had left their reservations to live in cities. Meanwhile, unemployment and alcoholism had blighted reservation life. Many tribes took advantage of their special legal status as independent nations to open bingo halls and gambling casinos for the general public on reservation lands, but the cycle of discrimination and poverty proved hard to break.

Cities and Suburbs
 America’s “alabaster cities” of song and story grew more sooty and less safe in the closing decades of the twentieth century. Crime was the great scourge of urban life. The rate of violent crimes committed in cities reached an all-time high in the drug-infested 1980s and then leveled off in the early 1990s. The number of violent crimes even began to decline substantially in many areas after 1995. Nevertheless, murders, robberies, and rapes remained shockingly common not only in cities but also in suburbs and rural areas. America imprisoned a larger fraction of its citizens than

MAKERS OF

AMERICA
TheAfricanThe Great Latinos American Migration 
T


 oday Mexican food is handed through fast-food drive-up windows in all ﬁ fty states, Spanishlanguage broadcasts ﬁ ll the airwaves, and the Latino community has its own telephone book, the Spanish Yellow Pages. Latinos send representatives to Congress and mayors to city hall, record hit songs, paint murals, and teach history. Latinos, among the fastest-growing segments of the U.S. population, include Puerto Ricans, frequent voyagers between their native island and northeastern cities; Cubans, many of them refugees from the communist dictatorship of Fidel Castro, concentrated in Miami and southern Florida; and Central Americans, ﬂeeing the ravages of civil war in Nicaragua and El Salvador. But the most populous group of Latinos derives from Mexico (see Figure 42.6). The ﬁ rst signiﬁcant numbers of Mexicans began heading for El Norte (“the North”) around 1910, when the upheavals of the Mexican Revolution stirred and shufﬂed the Mexican population into more or less constant ﬂux. Their northward passage was brieﬂy interrupted during the Great Depression, when thousands of Mexican nationals were deported. But immigration resumed during

Demonstrating for Immigrant
Rights, Los Angeles, 2007
 Latinos march in downtown Los Angeles in support of legalizing undocumented parents who have children born in the United States. U.S. law gives the right of citizenship to anyone born on American soil (“jus soli”), but not necessarily to the parents of that child.



 World War II, and since then a steady ﬂow of legal immigrants has passed through border checkpoints, joined by countless millions of their undocumented countrymen and countrywomen stealing across the frontier on moonless nights. For the most part, these Mexicans came to work in the ﬁelds, following the ripening crops northward to Canada through the summer and autumn months. In winter many headed back to Mexico, but some gathered instead in the cities of the Southwest—El Paso, Los Angeles, Houston, and San Bernardino. There they found regular work, even if lack of skills and racial discrimination often conﬁ ned them to manual labor. City jobs might pay less than farm labor, but the work was steady and offered the prospect of a stable home. Houses may have been shabby in the barrios, but these Mexican neighborhoods provided a sense of togetherness, a place to raise a family, and the chance to join a mutual aid society. Such societies, or mutualistas, sponsored baseball leagues, helped the sick and disabled, and defended their members against discrimination.

Puerto Rican
9.6%
 (3.4 million)

Cuban
3.5%
 (1.2 million)

Central or
South American and
Other Latino
28.4%
 (10.1 million)

Mexican
58.5%
 (20.6 million)

Figure 42.6 Sources of Latino Population in the United
States, 2000 (Source: Statistical Abstract of the United
States, 2003.)
Mexican American Farmworkers Pitting Apricots in
 Fruit Groves near Los Angeles, 1924

 Mexican immigrants lived so close to the border that their native country acted like a powerful magnet, drawing them back time and time again. Mexicans frequently returned to see relatives or visit the homes of their youth, and relatively few became U.S. citizens. Indeed, in many Mexican American communities, it was a badge of dishonor to apply for U.S. citizenship. The Mexican government, likewise inﬂuenced by the proximity of the two countries, intervened in the daily lives of its nationals in America, sometimes dis-

 couraging them from becoming citizens of their adopted country. As Anglo reformers attempted to Americanize the immigrants in the 1910s and 1920s, the Mexican consulate in Los Angeles launched a Mex icanization program. The consulate sponsored pa rades on Cinco de Mayo (“Fifth of May”), celebrating Mexico’s defeat of a French army at the Battle of Puebla in 1862, and opened special Spanish-language schools for children. Since World War II, the American-born generation has carried on the ﬁght for political representation, economic opportunity, and cultural preservation. Fresh arrivals from Mexico and from the other Latin American nations daily swell Latino communities across America. The census of 2000 revealed that Latinos are now the largest minority group in the United States, surpassing African Americans. As the United States moves through the twenty-ﬁ rst century, it is taking on a pronounced Spanish accent, and increasingly Latinos are making themselves a force to be reckoned with in American politics.

Young Latina Activists in East Boston,
 2004 Latinos have become increasingly inﬂuential voters, courted by Democratic and Republican candidates alike.



Chapter 42 The American People Face a New Century
Percent
Suburbs


 Central cities

74.8


77.5


80.3


69.0


63.3


56.1
47.8




30.9


44.6


Figure 42.7 Percent of
Total Population Living in
Metropolitan Areas and in
Their Central Cities and
Suburbs, 1910–2000


34.0


44.8


46.2


50.0


23.3
15.3


9.2


7.1


U.S.
Census Bureau, Decennial Census of Population, 1910 to  2000, compiled in Demographic Trends in the 20th Century, no. 2002.)

28.4


13.8


37.6


21.2


24.8


30.8


32.5


32.8


32.3


31.4


30.0


31.3


30.3






















 al most any other country in the world, and some desperate citizens resorted to armed vigilante tactics to protect themselves. The migration from cities to the suburbs was so swift and massive that by the mid-1990s a majority of Americans were suburban dwellers (see Figure 42.7). Jobs, too, became suburbanized. The nation’s rather brief “urban age” lasted little more than seven decades after 1920, and with its passing many observers saw a new fragmentation and isolation in American life. Some afﬂuent suburban neighborhoods walled themselves off behind elaborate security systems in “gated communities,” making it harder, perhaps, to sustain a sense of a larger and inclusive national community. By the ﬁrst decade of the twenty-ﬁrst century, the suburban rings around big cities such as New York, Chicago, Houston, and Washington, D.C., were becoming more racially and ethnically diverse, though individual schools and towns were often homogeneous. Suburbs grew fastest in the West and Southwest. In the outer orbits of Los Angeles, San Diego, Las Vegas, and Phoenix, builders of roads, water mains, and schools could barely keep up with the new towns sprouting across the hardscrabble landscapes. Newcomers came not only from nearby cities but from other regions of the United States as well. A momentous shift of the American population was under way,

 as inhabitants from the Northeast and the Rustbelt Midwest moved southward and westward to job opportunities and the sun. The Great Plains, where 60 percent of all counties were losing population as the twentieth century ended, faced the sharpest decline, hollowing out the traditional American heartland. By the early twenty-ﬁ rst century, the Great Plains contained fewer people than the Los Angeles basin, despite being ﬁve times the size of the entire state of Cal i fornia. Some major cities exhibited signs of renewal. Commercial redevelopment gained ground in cities such as New York, Boston, Chicago, San Francisco, and even the classic “city without a center,” Los Angeles. Wellto-do residents reclaimed once-fashionable neighborhoods and sent real estate values soaring. But these latter-day urban homesteaders struggled to make their cities genuine centers of residential integration. Cities stubbornly remained as divided by wealth and race as the suburban social landscape surrounding them.

Minority America
 Racial and ethnic tensions also exacerbated the problems of American cities. These stresses were especially evident in Los Angeles, which, like New York a cen-

Frustrations for African Americans


 tury earlier, was a magnet for minorities, especially immigrants from Asia and Latin America. When in 1992 a mostly white jury exonerated white Los Angeles police ofﬁcers who had been videotaped ferociously beating a black suspect, the minority neighborhoods of South Central Los Angeles erupted in rage. Arson and looting laid waste entire city blocks, and scores of people were killed. In a sobering demonstration of the complexity of modern American racial rivalries, many black rioters vented their anger at the white police and the judicial system by attacking Asian shopkeepers, who in turn formed armed patrols to protect their property. A decade later many a burnedout lot remained abandoned and weed-choked in neighborhoods still plagued by gang violence and the demoralizing effects of grinding poverty. The Los Angeles riots vividly testiﬁed to black skepticism about the American system of justice. Just three years later, again in Los Angeles, the televised spectacle of former football star O. J. Simpson’s murder trial fed white disillusionment with the state of race relations. After months of testimony that seemed to point to Simpson’s guilt, the jury acquitted him, presumably because certain Los Angeles police ofﬁcers involved in the case had been shown to harbor racist sentiments. In a later civil trial, another jury unanimously found Simpson liable for the “wrongful deaths” of his former wife and another victim. The reaction to the Simpson verdicts revealed the yawning chasm that separated white and black America, as most whites continued to believe Simpson guilty, while a majority of African Americans told pollsters that the original not-guilty verdict was justiﬁed. Similarly, complaints by African Americans that they had been unlawfully kept from the polls during the 2000 presidential election in Florida reﬂected the conviction of many blacks that they were still facing a Jim Crow South of systematic racial disfranchisement. American cities have always held an astonishing variety of ethnic and racial groups, but by the late twentieth century, minorities made up a majority of the population of many American cities, as whites ﬂed to the suburbs. In 2002, 52 percent of all blacks lived in central cities within metropolitan areas, compared with only 21 percent of whites. The most desperate black ghettos, housing a hapless “underclass” in the inner core of the old industrial cities, were especially problematic. Successful blacks who had beneﬁted from the civil rights revolution of the 1950s and 1960s followed whites to the suburbs, leaving a residue of the poorest poor in the old ghettos. Without a middle class



 to sustain community institutions like schools and small businesses, the inner cities, plagued by unemployment and drug addiction, seemed bereft of leadership, cohesion, resources, and hope. Single women headed about 45 percent of black families in 2002, more than three times the rate for whites. Many African American women, husbandless and jobless, necessarily depended on welfare to feed

 Still Fighting to Vote An African American father and daughter participate in a rally in downtown Miami several weeks after the November 2000 election to demand a recount of dismissed presidential election ballots. Many Florida blacks complained that election ofﬁcials had disproportionately disqualiﬁed their votes and unfairly turned them away from the polls, resurrecting the kind of obstacles that long had kept blacks from voting in the South.



Chapter 42 The American People Face a New Century


 their children. As social scientists increasingly emphasized the importance of the home environment for success in school, it became clear that many fatherless, impoverished African American children seemed consigned to suffer from educational handicaps that were difﬁcult to overcome. Some segments of the African American community did prosper in the wake of the civil rights gains of the 1950s and 1960s, although they still had a long hill to climb before reaching full equality. By 2006, 43 percent of all black families (compared to 61 percent of all white families) had incomes of at least $50,000, qualifying them (barely) as middle-class. Blacks continued to make headway in political life. The number of black elected ofﬁcials had risen above the nine thousand mark, including more than three dozen members of Congress and the mayors of several large cities. Voting tallies demonstrated that successful black politicians were moving beyond isolated racial constituencies and into the political mainstream by appealing to a wide variety of voters. In 1989 Virginians, only 15 percent of whom were black, chose L. Douglas Wilder as the ﬁ rst African American elected to serve as a state governor. In 1994 voters in Illinois made Carol Moseley-Braun the ﬁ rst African American woman elected to the U.S. Senate. In 2001 President George W. Bush appointed Colin Powell and Condoleezza Rice to top cabinet-level posts in his administration, as secretary of state and national security adviser, respectively. (Rice succeeded Powell as secretary of state in the second Bush administration.) And in the 2008 election, Senator Barack Obama, whose father was Kenyan, mounted the most successful campaign for president of any black American to date. Record turnouts gave him a decisive victory. By the early twenty-ﬁ rst century, blacks had also dramatically advanced into higher education, though the educational gap between blacks and whites stubbornly persisted. In 2006, 12.6 percent of blacks over age twenty-ﬁve had a bachelor’s degree, compared to 18.6 percent of whites (or 20.2 percent of non-Hispanic whites). The political assault against afﬁ rmative action in Cal i fornia and elsewhere in the 1990s only compounded the obstacles to advanced training for many young African Americans. But defenders of afﬁ rmative action chalked up a major victory in 2003 when the Supreme Court in a key case involving the University of Michigan afﬁ rmed that achieving racial diversity on college campuses was a legitimate means to secure a more equitable society. The Court preserved afﬁ rmative action in university admissions as long as

 schools avoided using quotas, point systems, or other mechanistic ways of diversifying their student bodies, though it remained uneasy about letting such programs endure indeﬁnitely. Justice Sandra Day O’Connor said, “We expect that 25 years from now, the use of racial preferences will no longer be necessary.”

E
Pluribus Plures  Controversial issues of color and culture also pervaded the realm of ideas in the late twentieth century. Echoing early-twentieth-century “cultural pluralists” like Horace Kallen and Randolph Bourne, many intellectuals after 1970 embraced the creed of “multiculturalism.” The new mantra stressed the need to preserve and promote, rather than squash, a variety of distinct ethnic and racial cultures in the United States. The nation’s classrooms became battlegrounds for the debate over America’s commitment to pluralism. Multiculturalists attacked the traditional curriculum as “Eurocentric” and advocated greater focus on the achievements of African Americans, Latinos, Asian Americans, and Native Americans. In response, critics charged that too much stress on ethnic difference would come at the expense of national cohesion and an appreciation of common American values. The Census Bureau further enlivened the debate when in 2000 it allowed respondents to identify themselves with more than one of the six standard racial categories (black, white, Latino, American Indian, Asian, and Native Hawaiian or other Paciﬁc Islander). Signifying a mounting revolution in attitudes toward race, nearly 7 million Americans chose to describe them-

 In 1990 the African American intellectual Shelby Steele (b. 1946) declared in his provocative book, The Content of Our Character,

“


 What is needed now is a new spirit of pragmatism in racial matters where blacks are seen simply as American citizens who deserve complete fairness and in some cases developmental assistance, but in no case special entitlements based on color. We need deracinated social policies that attack poverty rather than black poverty and that instill those values that make for self-reliance.

”


Literary Currents


 selves as biracial or multiracial. As recently as the 1960s, interracial marriage was still illegal in sixteen states. But by the early twenty-ﬁrst century, many Americans, including such celebrities as golfer Tiger Woods, actress Rosario Dawson, and Senator Barack Obama, were proclaiming their mixed heritage as a point of pride.

The Life of the Mind
 Despite the mind-sapping chatter of the “boob tube,” Americans in the early twenty-ﬁ rst century read more, listened to more music, and were better educated than ever before. Colleges awarded some 2.5 million degrees annually, and more than one person in ﬁve in the twenty-ﬁve-to-thirty-four-year-old age group boasted a college bachelor’s degree in 2006. (Nearly one in three had an associate’s degree.) This expanding mass of educated people lifted the economy to more advanced levels while creating consumers of “high culture.” Each year Americans made millions of visits to museums and patronized thousands of opera companies and symphony orchestras—as well as countless popular music groups. What Americans read said much about the state of American society in the new century. Among the



 most striking development in American letters was the rise of authors from ethnic groups now coming into their own. African American authors and artists also increasingly made their mark. Playwright August Wilson retold the history of black Americans in the twentieth century, with special emphasis on the psychic costs of the northward migration (Fences, 1985; Joe Turner’s Come and Gone, 1988; Jitney, 1998). Alice Walker gave ﬁctional voice to the experiences of black women in her hugely popular The Color Purple (1982). Toni Morrison wove a bewitching portrait of maternal affection in Beloved (1987) and in 1993 became the ﬁ rst African American woman to win the Nobel Prize for literature. Edward P. Jones inventively rendered the life of a slaveowning black family in his Pulitzer Prize–winning The Known World (2003). Native Americans, too, achieved literary recognition. Kiowa author N. Scott Momaday won a Pulitzer Prize for his portrayal of Indian life in House Made of Dawn (1968). James Welch wrote movingly about his Blackfoot ancestors in Fools Crow (1986). Asian American authors also ﬂourished, among them playwright David Hwang, novelist Amy Tan, and essayist Maxine Hong Kingston, whose Woman Warrior (1976) and China Men (1980) imaginatively reconstructed the obscure lives of the earliest Chinese immigrants. In Mona in the Promised Land (1996), Gish

Pulitzer Prize-Winning
Authors Edward P. Jones
 (left) and Jhumpa Lahiri



Chapter 42 The American People Face a New Century


 Jen guided her readers into the poignant comedy of suburban family relationships that was not uncommon for second-generation Asian Americans. Jhumpa Lahiri’s Interpreter of Maladies (1999) explored the sometimes painful relationship between immigrant Indian parents and their American-born children. Latino writers made their mark as well. Sandra Cisneros drew on her own life as a Mexican American child to evoke Latino life in working-class Chicago in The House on Mango Street (1984). Women writers and women’s themes forged to the ﬁctional forefront as the feminist movement advanced. Jane Smiley modeled her touching narrative of a midwestern farm family, A Thousand Acres (1991), on Shakespeare’s King Lear and followed up with a hilarious spoof of university life in Moo (1995). E. Annie Proulx won widespread acclaim with her comical yet tender portrayal of a struggling family in The Shipping News (1993), as well as with her moving tale of homoerotic love between two cowboys in Brokeback Mountain (1997). The rising interest in feminist and African American themes revived the popularity of a 1930s writer, Zora Neale Hurston, especially her naturalistic novel Their Eyes Were Watching God, ﬁ rst published in 1937. New York became the art capital of the world after World War II, as well-heeled Americans supported a

 In her touching novel The Joy Luck Club, Amy Tan (b. 1952) explored the complex dilemmas of growing up as a Chinese American:

“


 ‘A girl is like a young tree,’ [my mother] said. ‘You must stand tall and listen to your mother standing next to you. That is the only way to grow strong and straight. But if you bend to listen to other people, you will grow crooked and weak. . . .’ Over the years I learned to choose from the best opinions. Chinese people had Chinese opinions. American people had American opinions. And in almost every case, the American version was much better. It was only later that I discovered there was a serious ﬂaw with the American version. There were too many choices, so it was easy to get confused and pick the wrong thing.

”


 large number of painters and sculptors. The open and tradition-free American environment seemed especially congenial to the experimental mood of much modern art. Jackson Pollock pioneered abstract expressionism in the 1940s and 1950s, ﬂ inging paint on huge ﬂats stretched on his studio ﬂoor. Realistic representation went out the window, as artists like Pollock and Willem de Kooning strove to create “action paintings” that expressed the painter’s individuality and made the viewer a creative participant in deﬁning the painting’s meaning. Pop artists in the 1960s, notably Andy Warhol, canonized on canvas everyday items of consumer culture, such as soup cans. Claes Oldenburg tried to stun viewers into a new visual awareness with unfamiliar versions of familiar objects, such as giant plastic sculptures of pillow-soft telephones. On the stage, playwright David Mamet analyzed the barbarity of American capitalism in plays like Glengarry Glen Ross and American Buffalo, in which he crafted a kind of poetry from the sludge of American slang. Eve Ensler took a feminist commitment into new territory that blended comic intimacy and searing social commentary with her Vagina Monologues. The AIDS epidemic inspired Tony Kushner’s sensationally inventive Angels in America, a broad-ranging commentary, alternately hilarious and touching, about the condition of American life at the twentieth century’s end. Cuban American Nilo Cruz won a Pulitzer Prize in 2003 for Anna in the Tropics, his evocative play about immigrant cigar makers in 1930 Tampa. Film, the most characteristic American art form, continued to ﬂourish, especially as a wave of younger ﬁ lmmakers like George Lucas, Steven Spielberg, Spike Lee, Quentin Tarantino, and the Coen brothers, as well as the innovative documentary artist Ken Burns, made their inﬂuence felt. Architecture also beneﬁted from the building boom of the postwar era. Old master Frank Lloyd Wright produced strikingly original designs, as in the roundwalled Guggenheim Museum in New York. Louis Kahn employed stark geometric forms and basic building materials like brick and concrete to make beautiful, simple buildings. Eero Saarinen, the son of a Finnish immigrant, contributed a number of imaginative structures, including two Yale University residential colleges that evoked the at mosphere of an Italian hill town. Chinese-born I. M. Pei designed numerous graceful buildings on several college campuses, as well as the John F. Kennedy Library in Boston. “Postmodernists” such as Robert Venturi and Michael Graves, inspired by the decorative details of earlier historical

Artistic Achievements




MECHA
Mural, by Student Artists Directed by Sergio O’Cadiz, 1974 People have scribbled on walls since time immemorial, but in the 1960s and 1970s, mural painting emerged as a new form of American folk art. Drab buildings and bare fences, often in minority inner-city neighborhoods, were turned into huge canvases. This mural incorporates many Mexican American and Mexican themes, including the United Farm Workers’ bird symbol and a skeleton, a frequent motif in Mexican art. 
 styles, rejected the spare functionalism that had dominated modern architecture for much of the century. The ﬂ ight from stark modernism took fanciful forms in Frank Gehry’s use of luminous, undulating sheets of metallic skin in the widely hailed Guggenheim Museum in Bilbao, Spain, and the Walt Disney Concert Hall in Los Angeles.

The New Media
 By the early twenty-ﬁ rst century, the Internet had dramatically transformed daily life for most Americans. First created by the government for Cold War intelligence sharing, the World Wide Web spread like wildﬁ re through American homes, schools, and ofﬁces during the mid-1990s. The percentage of households with Internet access skyrocketed from 18 percent in

 1997 to over 70 percent in 2007. In rapidly increasing numbers, Americans turned to the Internet to communicate, shop, and even work. The “dot-com” explosion drove the tremendous economic boom of the late 1990s. (“Dot-com” refers to the uniform resource locater, or URL, sufﬁ x used for commercial Web sites.) Even as the “dot-com bubble” began to deﬂate, the Internet demonstrated its staying power. Many online start-up companies failed, but those that survived often became giants in retail (Amazon.com), information gathering (Google), and even ﬁ nance (E*Trade). The Internet reshaped the traditional corporate world as well. By the end of the 1990s, almost every business, group, or organization—from used-car dealers to sports teams to college arts groups—had its own Web site. Fulﬁ lling the promises of its early boosters, the Internet seemed to have a democratizing effect, spreading power and information among more and more



Chapter 42 The American People Face a New Century


 Americans. Young people in particular ﬂocked to social-networking sites like MySpace and Facebook to make connections, often with people in foreign countries. YouTube allowed everyday users to post home videos online for the whole world to see. And millions of people around the globe started a media revolution with their “Weblogs,” or “blogs.” “Bloggers” lent their voices to issues from foreign policy to college life, offering their beliefs and opinions without fear (and often without research). As the “blogosphere” grew, it posed a major challenge to the traditional media that had shaped Americans’ understanding of the news for hundreds of years. Supporters argued that this “new Media” added fresh voices and new per-

 spectives, but opponents questioned bloggers’ ex pertise and accused them of spreading misinformation. Blogs were not the only threat the Internet posed to the “mainstream media.” Americans became ever less willing to read the morning paper or watch the evening network news shows when they could access a welter of information on their computer screens. Cable news had challenged the old system since the 1980s, but the spread of the Internet made the twentyfour-hour news cycle a reality. Consumer demand pushed daily newspapers to offer their reporting online, often for free. Subscription rates plummeted, and ad sales—the engine that drives print journalism—fell off markedly. As with railroads and the telegraph in the nineteenth century, and radio and television in the twentieth century, computers and the Internet drove major readjustments in modern American economic, social, and cultural life.

The American Prospect


The Internet: Democratizing or Fragmenting?
 Time magazine named the users of the World Wide Web, MySpace, Facebook, YouTube, and other Internet attractions its “Person of the Year” in 2006 in recognition of the expanding ability to communicate with peers throughout the world. Critics worried, however, that the decline of older, integrative institutions like city newspapers and national network television would leave Americans with fewer forms of communication that united diverse populations.

 The American spirit pulsed with vitality in the early twenty-ﬁ rst century, but grave problems continued to plague the Republic. Women still fell short of ﬁ rst-class economic citizenship, and American society groped for ways to adapt the traditional family to the new realities of women’s work outside the home. A generation after the civil rights triumphs of the 1960s, full equality remained an elusive dream for countless Americans of color. Powerful foreign competitors challenged America’s premier economic status. As job opportunities shrank in some of the nation’s regions and expanded in others, as jobs shifted to cheaper labor markets abroad, and as giant corporations like Enron and WorldCom collapsed through corporate scandal, many Americans began to fear their economy as a treacherous landscape, even as it offered some of them astounding prosperity. The alarmingly unequal distribution of wealth and income threatened to turn America into a society of haves and have-nots, mocking the ideals of democracy and breeding seething resentments along the economic frontier that divided rich from poor. Environmental worries clouded the country’s future. Coal-ﬁ red electrical-generating plants helped form acid rain and probably contributed to the greenhouse effect, an ominous warming in the planet’s temperature. The unsolved problem of radioactive waste disposal hampered the development of nuclear power plants. The planet was being drained of oil, and disastrous accidents like the grounding and subsequent oil spill of the giant tanker Exxon Valdez in 1989

Future Challenges


 in Alaska’s pristine Prince William Sound demonstrated the ecological risks of oil exploration and transpor tation at sea. By the early twenty-ﬁ rst century, the once-lonely cries for alternative fuel sources had given way to mainstream public fascination with solar power and windmills, methane fuel, electric “hybrid” cars, and the pursuit of an affordable hydrogen fuel cell. Energy conservation remained another crucial but elusive strategy—much-heralded at the politician’s rostrum, but too rarely embodied in public policy, as witnessed in the Bush administration’s rejection of the Kyoto Treaty on global warming in 2001. A sudden spike in crude oil prices beginning in the spring of 2008, due to exploding demand in developing countries such as India and China, instability in the Middle East, and oil futures speculation, ﬁ nally galvanized public ofﬁcials, automakers, and consumers to pursue alternative sources of energy—for the sake of their own economic survival if not the planet’s. As the human family grew at an alarming rate on a shrinking globe, new challenges still faced America and its historical beliefs. The task of cleansing the earth of its abundant pollutants—including nuclear weapons—was one urgent mission confronting the American people in the new century. Another was seeking ways to resolve the ethnic and cultural conﬂ icts that erupted with renewed virulence around the globe in the wake of the Cold War’s end. At the same time, new opportunities beckoned in outer space and on inner-city streets, at the artist’s easel and in the concert hall, at the inventor’s bench and in the scientist’s laboratory, and in the unending quest for social justice, individual fulﬁ llment, and international peace. The terrorist attack on America on September 11, 2001, posed yet another challenge to the United States. Shielded for over two centuries against assaults on its soil, it would now have to preserve its security in a world made smaller by global communication and transportation, without altering its fundamental democratic values and way of life. The great danger posed by terrorism was not that Al Qaeda or other foreign groups would seize control of the country or any portion of its territory. It was, rather, that in ﬁghting terrorism, Americans would so compromise their freedoms at home and so isolate the country internationally that it would lose touch with its own guiding principles. Wars in Afghanistan and Iraq made these difﬁculties clear. The challenge was to enhance national security without eroding democratic liberties, to protect the country’s borders without preventing the arrival of



 desirable immigrants, and to use military force wisely without undermining America’s standing in the world. In facing those challenges, the world’s oldest republic had an extraordinary tradition of resilience and resourcefulness to draw on. Born as a revolutionary force in a world of conservatism, the United States stood in the twenty-ﬁ rst century as a conser vative force in a world of revolution. It had long held aloft the banner of liberal democracy in a world racked by revolutions of the right and left, including fascism, Nazism, and communism. Yet through it all, much that was truly revolutionary also remained a part of America’s liberal democratic heritage, as its people pioneered in revolutions against colonialism, racism, sexism, ignorance, and poverty. The dream of “making the world safe for democracy,” articulated nearly a century earlier by Woodrow Wilson at the end of the First World War, gained a new poignancy after September 11, when Americans expressed a yearning for greater equality, opportunity, and democracy in the Middle East—all in the hope of diminishing the root causes of international terrorism. The capacity to nurture progress abroad, however, depended on the ability of Americans to improve their own country, and to do so in the midst of new threats to their own security. As Wilson wrote in 1893, long before he became president, “Democratic institutions are never done; they are like living tissue, always a-making. It is a strenuous thing, this of living the life of a free people.”

To Learn More
 Nancy Altman, The Battle for Social Security: From FDR’s Vision to Bush’s Gamble (2005) William Chafe, The Paradox of Change: American Women in the 20th Century (1991) David Dent, In Search of Black America: Discovering the African-American Dream (2000) Barbara Ehrenreich, Nickel and Dimed: On (Not) Getting By in America (2001) Bill Ong Hing, Deﬁning America Through Immigration Policy (2004) Paul Krugman, The Great Unraveling: Losing Our Way in the New Century (2003) Katherine Newman, A Different Shade of Gray: Midlife and Beyond in the Inner City (2003) George Sanchez, Becoming Mexican American (1989) A complete, annotated bibliography for this chapter—along with brief descriptions of the People to Know and additional review materials—may be found at www.cengage.com/history/kennedy/ampageant14e

